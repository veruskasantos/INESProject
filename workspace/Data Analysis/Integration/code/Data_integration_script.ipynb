{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data integration script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this task is to integrate in the same file the following data:\n",
    "- GPS;\n",
    "- Weather;\n",
    "- Waze;\n",
    "- GTFS\n",
    "\n",
    "Example of final file attributes (to use in ML algorithms):\n",
    "* **route, gps_id, bus_code, gps_timestamp, gps_lat, gps_lon, trip_problem_code, *stop_id, scheduled_timestamp, scheduled_headway, actual_headway, precipitation, distance_gps_station, waze_attributes* **\n",
    "\n",
    "Bulma output\n",
    "* **trip_number/no_shape_code, route, shape_id/-, shape_sequence/-, shape_lat/-, shape_lon/-, gps_id, bus_code, gps_timestamp, gps_lat, gps_lon, distance_to_shape_point/-, threshold_distance_gps_shape/-, trip_problem_code, *stop_id, scheduled_timestamp, scheduled_headway, actual_headway, precipitation, distance_gps_station, waze_attributes* **\n",
    "\n",
    "**TODO:** check if it is better to calculate the headway with relation to the first bus.\n",
    "\n",
    "The task has the following steps:\n",
    "### 1. Clean the data (removing missing/wrong data); OK\n",
    "1.1 Separate Recife files and convert coordinates\n",
    "\n",
    "1.2 Remove different cities of Waze\n",
    "\n",
    "1.3 Remove Recife GPS data without route, lat or lon\n",
    "\n",
    "### 2. Label shape file with route type (low/high frequency) OK\n",
    "2.1 Calculate headway median of each route and headway median of the city\n",
    "\n",
    "2.2 Update route.txt e shapes.csv\n",
    "\n",
    "### 3. Update and run BULMA (Integration of GPS and GTFS); OK\n",
    "3.1. Filter GPS data to common attributes: bus.code, latitude, longitude, timestamp, line.code, gps.id\n",
    "\n",
    "After this, run for CG and Curitiba too.\n",
    "### 4. Update and run BUSTE (interpolate stops timestamp) OK\n",
    "### 5. Label each GPS with headway value and BB (headway, BB, id_bus_bb)\n",
    "### 6. Label with precipitation (precipitation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utm\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from numpy import median\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELIMITER = ','\n",
    "NEW_EMPTY_LINE = '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data example\n",
    "\n",
    "#### GPS\n",
    "- bus_code\n",
    "- timestamp\n",
    "- route\n",
    "- latitude\n",
    "- longitude\n",
    "\n",
    "#### Weather\n",
    "\n",
    "#### Waze\n",
    "\n",
    "#### GTFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing GPS data of Recife to separate files per day and to convert coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertCoordinates(x, y):\n",
    "    if (x == '-' or x == '0' or y == '-' or y == '0'):\n",
    "        return ['-', '-']\n",
    "    \n",
    "    return utm.to_latlon(long(x), long(y), 25, 'M')\n",
    "    \n",
    "def separateGPSFilePerMonth(file_path):\n",
    "    october_file = open(file_path + 'GPS_data_october.csv', 'w')\n",
    "    november_file = open(file_path + 'GPS_data_november.csv', 'w')\n",
    "    december_file = open(file_path + 'GPS_data_december.csv', 'w')\n",
    "    columns_name = \"Unidad\" + DELIMITER +  \"Instante\" + DELIMITER + \"Estado\" + DELIMITER + \"Comunica\" + DELIMITER + \"CoordX\" + DELIMITER + \"CoordY\" + DELIMITER + \"Linea\" + DELIMITER + \"Ruta\" + DELIMITER + \"Posicion\" + DELIMITER + \"Viaje\" + DELIMITER + \"Velocidad\"\n",
    "    october_file.write(columns_name + NEW_EMPTY_LINE)\n",
    "    november_file.write(columns_name + NEW_EMPTY_LINE)\n",
    "    december_file.write(columns_name + NEW_EMPTY_LINE)\n",
    "    \n",
    "    october = '2018-10'\n",
    "    november = '2018-11'\n",
    "    december = '2018-12'\n",
    "    \n",
    "    file_name = file_path + \"GPS_data.csv\"\n",
    "    with open(file_name, 'r') as gps_data:\n",
    "        next(gps_data)\n",
    "        for line in gps_data:\n",
    "            line_splitted = line.split(DELIMITER)\n",
    "            date = line_splitted[1]\n",
    "            lat = line_splitted[4]\n",
    "            lon = line_splitted[5]\n",
    "            new_coordinates = convertCoordinates(lat, lon)\n",
    "            \n",
    "            new_line = line_splitted[0] + DELIMITER + line_splitted[1] + DELIMITER + line_splitted[2] + DELIMITER + line_splitted[3] + DELIMITER + str(new_coordinates[0]) + DELIMITER + str(new_coordinates[1]) + DELIMITER + line_splitted[6] + DELIMITER + line_splitted[7] + DELIMITER + line_splitted[8] + DELIMITER + line_splitted[9] + DELIMITER + line_splitted[10]\n",
    "            \n",
    "            if (october in date):\n",
    "                october_file.write(new_line)\n",
    "            elif (november in date):\n",
    "                november_file.write(new_line)\n",
    "            elif (december in date):\n",
    "                december_file.write(new_line)\n",
    "\n",
    "def separateGPSFilePerDay(file_path):\n",
    "    columns_name = \"Unidad\" + DELIMITER +  \"Instante\" + DELIMITER + \"Estado\" + DELIMITER + \"Comunica\" + DELIMITER + \"CoordX\" + DELIMITER + \"CoordY\" + DELIMITER + \"Linea\" + DELIMITER + \"Ruta\" + DELIMITER + \"Posicion\" + DELIMITER + \"Viaje\" + DELIMITER + \"Velocidad\"\n",
    "    file_name = file_path + \"GPS_data_october.csv\"\n",
    "    date_lines_dict = {}\n",
    "    with open(file_name, 'r') as gps_data:\n",
    "        next(gps_data)\n",
    "        for line in gps_data:\n",
    "            line_splitted = line.split(DELIMITER)\n",
    "            date_time = line_splitted[1]\n",
    "            date = date_time.split(' ')[0]\n",
    "            \n",
    "            if (date not in date_lines_dict):\n",
    "                date_lines_dict[date] = []\n",
    "            \n",
    "            date_lines_dict[date].append(line)\n",
    "            \n",
    "    \n",
    "    for key in date_lines_dict:\n",
    "        new_file = open(file_path + 'GPS_data_' + key + '.csv', 'w')\n",
    "        new_file.write(columns_name + NEW_EMPTY_LINE)\n",
    "        \n",
    "        for data_per_day in date_lines_dict[key]:\n",
    "            new_file.write(data_per_day)\n",
    "            \n",
    "        new_file.close()\n",
    "            \n",
    "file_path = os.getcwd() + \"/../data/input/Recife/GPS/\"\n",
    "\n",
    "separateGPSFilePerMonth(file_path)\n",
    "\n",
    "separateGPSFilePerDay(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Clean the data\n",
    "Removing missing/wrong data\n",
    "\n",
    "#### 1.1 Waze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waze\n",
    "# Removing lines from different city\n",
    "\n",
    "def removeDifferentCity(dir_name, city_label):\n",
    "    \n",
    "    for file_name in os.listdir(dir_name):\n",
    "        \n",
    "        if file_name.endswith(\".csv\"): # to get just files\n",
    "            file_path = dir_name + file_name\n",
    "\n",
    "            new_file = open(dir_name + 'clean/' + file_name, 'w')\n",
    "\n",
    "            with open(file_path, 'r') as waze_data:\n",
    "                new_file.write(next(waze_data)) # write the header\n",
    "                \n",
    "                for line in waze_data:\n",
    "                    line_splitted = line.split(',')\n",
    "                    city = line_splitted[1]\n",
    "\n",
    "                    if (city_label in city):\n",
    "                        new_file.write(line) # to add just lines of the city\n",
    "\n",
    "                new_file.close()\n",
    "            \n",
    "# Alert: create the folder 'clean', set the path and the city name            \n",
    "dir_path = os.getcwd() + \"/../data/input/Recife/Waze/\"\n",
    "city = 'Recife'\n",
    "removeDifferentCity(dir_path, city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 GPS\n",
    "\n",
    "Removing Recife data without *linea* (route) or *CoordX* or *CoordY*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPS - Recife\n",
    "# Removing lines without linea or CoordX or CoordY\n",
    "\n",
    "def cleanRecifeGPS(dir_path):\n",
    "    for file_name in os.listdir(dir_path):\n",
    "        \n",
    "        if file_name.endswith(\".csv\"): # to get just files\n",
    "            file_path = dir_path + file_name\n",
    "            \n",
    "            new_file = open(dir_path + 'clean/' + file_name, 'w')\n",
    "\n",
    "            with open(file_path, 'r') as gps_data:\n",
    "                new_file.write(next(gps_data)) # write the header\n",
    "                \n",
    "                for line in gps_data:\n",
    "                    line_splitted = line.split(',')\n",
    "                    route = line_splitted[6]\n",
    "                    lat = line_splitted[4]\n",
    "                    lon = line_splitted[5]\n",
    "\n",
    "                    if (route != '' and lat != '-' and lat != '' and lon != '-' and lon != ''):\n",
    "                        new_file.write(line) # to add just lines not empty\n",
    "\n",
    "                new_file.close()\n",
    "                \n",
    "# Alert: create the folder 'csv' \n",
    "dir_path = os.getcwd() + \"/../data/input/Recife/GPS/\"\n",
    "cleanRecifeGPS(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPS - Curitiba\n",
    "# Converting json file to csv file\n",
    "\n",
    "# Alert: first, replace }{ by },{ \n",
    "# sed -i ':a;N;$!ba;s/}/},/g' *.json\n",
    "\n",
    "def convertJSON2CSV(dir_path):\n",
    "    columns_name = \"bus_code\" + DELIMITER + \"lat\" + DELIMITER + \"lon\" + DELIMITER + \"timestamp\" + DELIMITER + \"route\"\n",
    "    \n",
    "    for file_name in os.listdir(dir_path):\n",
    "        \n",
    "        if file_name.endswith(\".json\"): # to get just files\n",
    "            file_path = dir_path + file_name\n",
    "            \n",
    "            new_file = open(dir_path + 'csv/' + file_name.split('.')[0] + '.csv', 'w')\n",
    "\n",
    "            new_file.write(columns_name + NEW_EMPTY_LINE)\n",
    "            \n",
    "            with open(file_path, 'r') as gps_data:\n",
    "                next(gps_data) # skip empty line \n",
    "                for line in gps_data:\n",
    "                    line_splitted = line.split(',')\n",
    "                    bus_code = line_splitted[0].split('\":')[1]\n",
    "                    lat = line_splitted[1].split('\":')[1]\n",
    "                    lon = line_splitted[2].split('\":')[1]\n",
    "                    timestamp = line_splitted[3].split('\":')[1]\n",
    "                    route = line_splitted[4].split('\":')[1][:-1]\n",
    "                    \n",
    "                    new_line = bus_code + DELIMITER + lat + DELIMITER + lon + DELIMITER + timestamp + DELIMITER + route\n",
    "                    \n",
    "                    new_file.write(new_line + NEW_EMPTY_LINE)\n",
    "            \n",
    "dir_path = os.getcwd() + \"/../data/input/Curitiba/GPS/\"\n",
    "convertJSON2CSV(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Label shape file with route type\n",
    "\n",
    "Label shape file with route type: high frequency or low frequency based on *headway median of the city (h_median)*.\n",
    "\n",
    "- **High frequency:** headway mean of the route <= h_median\n",
    "- **Low frequency:** headway mean of the route > h_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"trips_file_example.png\">\n",
    "\n",
    "The *stop_times* file has the information:\n",
    "- Buses: all the schedules of the bus are grouped, e.g. the schedules of the first bus are the firsts lines (from 5:00 to 23:00)\n",
    "- Headway: the diference of the *arrival_time* of the bus and the follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge: how to separate different buses to compare headways?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alert: choose the city to label the gtfs\n",
    "\n",
    "city = \"CG\"\n",
    "# city = \"Curitiba\"\n",
    "# city = \"Recife\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alert: Set the path with the city name            \n",
    "dir_path = os.getcwd() + \"/../data/input/\" + city + \"/GTFS/\"\n",
    "trips_file = 'trips.txt'\n",
    "stop_times_file = 'stop_times.txt'\n",
    "\n",
    "# Read trips.txt to get the route of the trips\n",
    "def getRouteServiceTripsMap():\n",
    "    route_service_trips_map = {}\n",
    "    \n",
    "    with open(dir_path + trips_file, 'r') as trips_data:\n",
    "        next(trips_data) # skip header\n",
    "        for line in trips_data:\n",
    "            splitted_line = line.split(',')\n",
    "            route = splitted_line[0]\n",
    "            service_id = splitted_line[1]\n",
    "            trip_id = splitted_line[2]\n",
    "            \n",
    "            if (route not in route_service_trips_map):\n",
    "                route_service_trips_map[route] = {}\n",
    "                \n",
    "            if (service_id not in route_service_trips_map[route]):\n",
    "                route_service_trips_map[route][service_id] = []\n",
    "            \n",
    "            route_service_trips_map[route][service_id].append(trip_id)\n",
    "    \n",
    "#     print(route_trips_map)\n",
    "    \n",
    "    return route_service_trips_map\n",
    "    \n",
    "\n",
    "# Read stop_times.txt to get the stop_times of each trip\n",
    "# The output is: {route: {service_id: {stop_id: [time1, ... timen]}}} \n",
    "def getTripsStopsTimesMap(route_service_trips_map):\n",
    "    route_service_stops_times = {}\n",
    "    \n",
    "    with open(dir_path + stop_times_file, 'r') as stops_times_data:\n",
    "        next(stops_times_data) # skip header\n",
    "        \n",
    "        for line in stops_times_data:\n",
    "            splitted_line = line.split(',')\n",
    "            trip_id = splitted_line[0]\n",
    "            stop_id = splitted_line[3]\n",
    "            arrival_time = splitted_line[1]\n",
    "            \n",
    "            # get the route of the trip \n",
    "            for route_key, service_trips in route_service_trips_map.items():\n",
    "                \n",
    "                for service_key, trips in service_trips.items():\n",
    "                    if trip_id in trips:\n",
    "                        route = route_key\n",
    "                        service = service_key\n",
    "                        break\n",
    "\n",
    "            if (route not in route_service_stops_times):\n",
    "                route_service_stops_times[route] = {}\n",
    "                \n",
    "            if (service not in route_service_stops_times[route]):\n",
    "                route_service_stops_times[route][service] = {}\n",
    "            \n",
    "            if (stop_id not in route_service_stops_times[route][service]):\n",
    "                route_service_stops_times[route][service][stop_id] = []\n",
    "            \n",
    "            route_service_stops_times[route][service][stop_id].append(arrival_time)\n",
    "                    \n",
    "#     print(route_stops_times['34'])\n",
    "    return route_service_stops_times\n",
    "\n",
    "\n",
    "# Calculate the headway(difference between two timestamps) in seconds\n",
    "def getHeadway(time1, time2):\n",
    "    t1 = datetime.strptime(time1, \"%H:%M:%S\")\n",
    "    t2 = datetime.strptime(time2, \"%H:%M:%S\")\n",
    "    difference = t2 - t1\n",
    "    \n",
    "    return difference.seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_service_trips_map = getRouteServiceTripsMap()\n",
    "route_service_stops_times = getTripsStopsTimesMap(route_service_trips_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate headway median of each route and headway median of the city\n",
    "# comparing times of the same stop, route and service\n",
    "def calculateRoutesHeadways(route_service_stops_times):\n",
    "    route_headway_median_map = {}\n",
    "    sum_headways_city = []\n",
    "    \n",
    "    for route, services in route_service_stops_times.items():\n",
    "        sum_headways_route = []\n",
    "\n",
    "        for service, stopstimes in services.items():\n",
    "\n",
    "            for stops, times in stopstimes.items():\n",
    "                last_time = 0\n",
    "\n",
    "                # Order times before to iterate\n",
    "                ordered_times = sorted(times, key=lambda d: map(int, d.split(':')))\n",
    "                print(route, stops, ordered_times)\n",
    "                for time in ordered_times:\n",
    "\n",
    "                    # skip the first timestamp or wrong data\n",
    "                    if (last_time != 0 and not time.startswith('24:') and not last_time.startswith('24:') \n",
    "                        and not time.startswith('25:') and not last_time.startswith('25:') \n",
    "                        and not time.startswith('26:') and not last_time.startswith('26:')\n",
    "                        and not time.startswith('27:') and not last_time.startswith('27:')\n",
    "                        and not time.startswith('28:') and not last_time.startswith('28:')):\n",
    "                        \n",
    "                        # mean doesn't work because some routes run in specific times\n",
    "                        headway = getHeadway(last_time, time)\n",
    "\n",
    "                        sum_headways_route.append(headway)\n",
    "\n",
    "                    last_time = time\n",
    "\n",
    "        # calculate the median headway of the route\n",
    "        if (len(sum_headways_route) > 0):\n",
    "            headway_route = median(sum_headways_route)\n",
    "            route_headway_median_map[route] = headway_route\n",
    "\n",
    "            sum_headways_city.append(headway_route)\n",
    "            \n",
    "    median_headway_city = median(sum_headways_city)\n",
    "    return (median_headway_city, route_headway_median_map)\n",
    "    \n",
    "median_headway_city, route_headway_median_map = calculateRoutesHeadways(route_service_stops_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update routes.txt file with frequency (high or low) label\n",
    "# based on its median headway and the median headway city\n",
    "def updateRoutesFile(file_path, median_headway_city, route_headway_median_map):\n",
    "    \n",
    "    new_routes_file = open(file_path + 'routes_label.txt', 'w')\n",
    "    \n",
    "    with open(file_path + 'routes.txt', 'r') as routes_data:\n",
    "        columns_name = next(routes_data).split(DELIMITER)\n",
    "        \n",
    "        new_routes_file.write(columns_name[0] + DELIMITER + columns_name[1] + DELIMITER + columns_name[2]\n",
    "                               + DELIMITER + columns_name[3] + DELIMITER + columns_name[4] + DELIMITER \n",
    "                              + columns_name[5] + DELIMITER + columns_name[6] + DELIMITER + columns_name[7] \n",
    "                               + DELIMITER + 'frequency' + DELIMITER + columns_name[8]) # write header \n",
    "        \n",
    "        for line in routes_data:\n",
    "            line_splitted = line.split(DELIMITER)\n",
    "            route = str(line_splitted[0])\n",
    "            \n",
    "            # When there was no data to calculate headway or when route headway > city headway\n",
    "            label = 'low_frequency'\n",
    "            headway = '-'\n",
    "            \n",
    "            if (route in route_headway_median_map):\n",
    "                headway = route_headway_median_map[route]\n",
    "                if (headway <= median_headway_city):\n",
    "                    label = 'high_frequency'\n",
    "            \n",
    "            print('City: ' + city, 'Route: ' + route, 'headway_city: ' + str(median_headway_city), \n",
    "                  'headway_route: ' + str(headway), 'label: ' + label)\n",
    "            \n",
    "            new_line = line_splitted[0] + DELIMITER + line_splitted[1] + DELIMITER + line_splitted[2] + DELIMITER + line_splitted[3] + DELIMITER + line_splitted[4] + DELIMITER + line_splitted[5] + DELIMITER + line_splitted[6] + DELIMITER + line_splitted[7] + DELIMITER + label + DELIMITER + line_splitted[8]\n",
    "            new_routes_file.write(new_line)\n",
    "            \n",
    "    new_routes_file.close()\n",
    "    \n",
    "    print(\"Saving routes_label.txt with route frequency.\")\n",
    "\n",
    "# Alert: change the city name\n",
    "file_path = os.getcwd() + \"/../data/input/\" + city + \"/GTFS/\"\n",
    "updateRoutesFile(file_path, median_headway_city, route_headway_median_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataFromCSV(file_path):\n",
    "    file_data = []\n",
    "    \n",
    "    with open(file_path, 'r') as data:\n",
    "        columns_name = next(data) # skip header\n",
    "        \n",
    "        for line in data:\n",
    "            file_data.append(line)\n",
    "            \n",
    "    return file_data\n",
    "\n",
    "\n",
    "def saveData2CSV(file_path, new_data, header):\n",
    "    new_file_data = open(file_path, 'w')\n",
    "    new_file_data.write(header + NEW_EMPTY_LINE)\n",
    "    \n",
    "    for line in new_data:\n",
    "        new_file_data.write(line + NEW_EMPTY_LINE)\n",
    "        \n",
    "    new_file_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving new shapes.csv with route id and frequency - CG\n"
     ]
    }
   ],
   "source": [
    "# Add route id and frequency to shapes.txt file\n",
    "\n",
    "file_path = os.getcwd() + \"/../data/input/\" + city + \"/GTFS/\"\n",
    "\n",
    "def updateShapeFile(file_path):\n",
    "    shape_path = file_path + \"shapes.txt\"\n",
    "    trips_path = file_path + \"trips.txt\"\n",
    "    routes_path = file_path + \"routes_label.txt\"\n",
    "    \n",
    "    new_shape_file = [];\n",
    "    \n",
    "    # Create a map {shapes: route} from trips.txt\n",
    "    route_shape_map = {}\n",
    "    trips_data = readDataFromCSV(trips_path)\n",
    "    for trip in trips_data:\n",
    "        attributes = trip.split(DELIMITER)\n",
    "        route = attributes[0]\n",
    "        \n",
    "        if (city == \"Recife\"):\n",
    "            shapeID = attributes[6][0:-2] # to remove \"\\r\\n\"\n",
    "        else:\n",
    "            shapeID = attributes[7][0:-1] # to remove \"\\n\"\n",
    "        \n",
    "        if (shapeID not in route_shape_map):\n",
    "            route_shape_map[shapeID] = route # assuming that a shape has one route\n",
    "            \n",
    "    # Create a map {route: frequency} from routes_label.txt\n",
    "    route_frequency_map = {}\n",
    "    routes_data = readDataFromCSV(routes_path)\n",
    "    for routes in routes_data:\n",
    "        attributes = routes.split(DELIMITER)\n",
    "        route = attributes[0]\n",
    "        frequency = attributes[8]\n",
    "        \n",
    "        if (city == \"CG\"): # the gps data route is route_short_name\n",
    "            route_gps = attributes[2] # route_short_name\n",
    "            \n",
    "            if (route not in route_frequency_map):\n",
    "                route_frequency_map[route] = frequency + \"-\" + route_gps\n",
    "            \n",
    "        else:\n",
    "            if (route not in route_frequency_map):\n",
    "                route_frequency_map[route] = frequency\n",
    "    \n",
    "\n",
    "    shapes_data = readDataFromCSV(shape_path)\n",
    "    for shape in shapes_data:\n",
    "        attributes = shape.split(DELIMITER)\n",
    "        shapeID = attributes[0]\n",
    "        \n",
    "        route = \"-\"\n",
    "        frequency = \"-\"\n",
    "        if (shapeID in route_shape_map):\n",
    "            route = route_shape_map[shapeID]\n",
    "        \n",
    "        other_attributes = shape[0:-1]\n",
    "        if (city == \"Recife\"):\n",
    "            other_attributes = shape[0:-2]\n",
    "        \n",
    "        new_line = route + DELIMITER + other_attributes + DELIMITER + frequency # for shape without route\n",
    "        \n",
    "        if (route in route_frequency_map):\n",
    "            if (city == \"CG\"):\n",
    "                frequency_route = route_frequency_map[route].split(\"-\")\n",
    "                frequency = frequency_route[0]\n",
    "                route_id = frequency_route[1]\n",
    "                shape_distance_traveled = float(attributes[4]) * 1000 # converting km to m\n",
    "                \n",
    "                other_attributes = attributes[0] + DELIMITER + attributes[1] + DELIMITER + attributes[2] + DELIMITER + attributes[3] + DELIMITER + str(shape_distance_traveled)\n",
    "                \n",
    "                new_line = route_id + DELIMITER + other_attributes + DELIMITER + frequency\n",
    "                \n",
    "            else:\n",
    "                frequency = route_frequency_map[route]\n",
    "                new_line = route + DELIMITER + other_attributes + DELIMITER + frequency\n",
    "              \n",
    "        new_shape_file.append(new_line)\n",
    "        \n",
    "    header = \"route,shape_id,shape_pt_lat,shape_pt_lon,shape_pt_sequence,shape_dist_traveled,route_frequency\"\n",
    "    \n",
    "    saveData2CSV(file_path + \"shapes1.csv\", new_shape_file, header)\n",
    "    print(\"Saving new shapes.csv with route id and frequency - \" + city)\n",
    "\n",
    "updateShapeFile(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each stop time belongs to one trip, i.e. the total os trips is the total os time stamps there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "- In general, the scheduled headway of Curitiba is 1413 seconds (23 minutes).\n",
    "- In general, the scheduled headway of Campina Grande is 1140.0 seconds (19 minutes).\n",
    "- In general, the scheduled headway of Recife is 5115.0 seconds (1h42 minutes). (GTFS out of date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Update and run BULMA/BUSTE (Integration between GPS and GTFS)\n",
    "\n",
    "We need to use BULMA to correct the GPS position in the street and some cities has multiple shapes for the same route."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** City - Execution time - #Shapes per route **\n",
    "\n",
    "Curitiba - 15 min (per file - day) - 2+\n",
    "\n",
    "Campina Grande - 30s (per file - day) - 2+\n",
    "\n",
    "Recife - 2 min (per file - day) - 2(+?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar novo código Spark para:\n",
    "\n",
    "After BULMA execution, add to the output:\n",
    "- 3.6. The precipitation value (according to the hour and less distance)\n",
    "- 3.7. The waze values (according to the same street and time)\n",
    "- 3.8. The headway and BB value.\n",
    "\n",
    "THE END OF THE INTEGRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 3.4, 3.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
