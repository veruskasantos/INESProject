{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import gammaln, betaln\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, ClassifierMixin\n",
    "from sklearn.metrics import pairwise_kernels\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "import csv\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/lsorber/auto-ls-svm/blob/master/autolssvm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69884, 420)\n",
      "(69884, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route</th>\n",
       "      <th>tripNum</th>\n",
       "      <th>shapeSequence</th>\n",
       "      <th>shapeLat</th>\n",
       "      <th>shapeLon</th>\n",
       "      <th>distanceTraveledShape</th>\n",
       "      <th>busCode</th>\n",
       "      <th>gpsPointId</th>\n",
       "      <th>gpsLat</th>\n",
       "      <th>gpsLon</th>\n",
       "      <th>...</th>\n",
       "      <th>alertTypeSB_ACCIDENT</th>\n",
       "      <th>alertTypeSB_CHIT_CHAT</th>\n",
       "      <th>alertTypeSB_HAZARD</th>\n",
       "      <th>alertTypeSB_JAM</th>\n",
       "      <th>alertTypeSB_NORMAL</th>\n",
       "      <th>alertTypeSB_POLICE</th>\n",
       "      <th>alertTypeSB_ROAD_CLOSED</th>\n",
       "      <th>jamBlockTypeSB_-</th>\n",
       "      <th>jamBlockTypeSB_NORMAL</th>\n",
       "      <th>jamBlockTypeSB_ROAD_CLOSED_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.118068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084945</td>\n",
       "      <td>0.264128</td>\n",
       "      <td>0.439400</td>\n",
       "      <td>0.010487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.265656</td>\n",
       "      <td>0.439493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.118068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084965</td>\n",
       "      <td>0.264428</td>\n",
       "      <td>0.443488</td>\n",
       "      <td>0.014304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.265956</td>\n",
       "      <td>0.444051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.118068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084972</td>\n",
       "      <td>0.263625</td>\n",
       "      <td>0.448606</td>\n",
       "      <td>0.018030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.264915</td>\n",
       "      <td>0.448957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.118068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084979</td>\n",
       "      <td>0.261608</td>\n",
       "      <td>0.458297</td>\n",
       "      <td>0.025182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.263352</td>\n",
       "      <td>0.456961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.118068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084985</td>\n",
       "      <td>0.260228</td>\n",
       "      <td>0.463266</td>\n",
       "      <td>0.028953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261792</td>\n",
       "      <td>0.463170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 420 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      route  tripNum  shapeSequence  shapeLat  shapeLon  \\\n",
       "0  0.118068      0.0       0.084945  0.264128  0.439400   \n",
       "1  0.118068      0.0       0.084965  0.264428  0.443488   \n",
       "2  0.118068      0.0       0.084972  0.263625  0.448606   \n",
       "3  0.118068      0.0       0.084979  0.261608  0.458297   \n",
       "4  0.118068      0.0       0.084985  0.260228  0.463266   \n",
       "\n",
       "   distanceTraveledShape  busCode  gpsPointId    gpsLat    gpsLon  ...  \\\n",
       "0               0.010487      0.0    0.000006  0.265656  0.439493  ...   \n",
       "1               0.014304      0.0    0.000009  0.265956  0.444051  ...   \n",
       "2               0.018030      0.0    0.000010  0.264915  0.448957  ...   \n",
       "3               0.025182      0.0    0.000014  0.263352  0.456961  ...   \n",
       "4               0.028953      0.0    0.000000  0.261792  0.463170  ...   \n",
       "\n",
       "   alertTypeSB_ACCIDENT  alertTypeSB_CHIT_CHAT  alertTypeSB_HAZARD  \\\n",
       "0                   0.0                    0.0                 0.0   \n",
       "1                   0.0                    0.0                 0.0   \n",
       "2                   0.0                    0.0                 0.0   \n",
       "3                   0.0                    0.0                 0.0   \n",
       "4                   0.0                    0.0                 0.0   \n",
       "\n",
       "   alertTypeSB_JAM  alertTypeSB_NORMAL  alertTypeSB_POLICE  \\\n",
       "0              0.0                 1.0                 0.0   \n",
       "1              0.0                 1.0                 0.0   \n",
       "2              0.0                 1.0                 0.0   \n",
       "3              0.0                 1.0                 0.0   \n",
       "4              0.0                 1.0                 0.0   \n",
       "\n",
       "   alertTypeSB_ROAD_CLOSED  jamBlockTypeSB_-  jamBlockTypeSB_NORMAL  \\\n",
       "0                      0.0               0.0                    1.0   \n",
       "1                      0.0               0.0                    1.0   \n",
       "2                      0.0               0.0                    1.0   \n",
       "3                      0.0               0.0                    1.0   \n",
       "4                      0.0               0.0                    1.0   \n",
       "\n",
       "   jamBlockTypeSB_ROAD_CLOSED_EVENT  \n",
       "0                               0.0  \n",
       "1                               0.0  \n",
       "2                               0.0  \n",
       "3                               0.0  \n",
       "4                               0.0  \n",
       "\n",
       "[5 rows x 420 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../../data/output/normalized_data_X_5p.csv'\n",
    "y_path = '../../data/output/y_5p.csv'\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "y = pd.read_csv(y_path)\n",
    "print(data.shape)\n",
    "print(y.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making training and test data: 80% Training, 20% Test\n",
    "random.seed(15) #to get always the same set\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(data, y, test_size=0.20, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "TODO:\n",
    "- Large scale implementation (with support for sparse matrices)\n",
    "- Change kernel radius definition from a multiple k of the nearest neighbour\n",
    "  distance to the k-nearest neighbour distance.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def robust_normalizer(X, one_sided_extrema=0.05, hypercube_edge_length=1.0):\n",
    "    \"\"\"Compute a robust translation and scale parameter.\"\"\"\n",
    "    m = np.median(X, axis=0)\n",
    "    s = np.amax(np.abs(np.percentile(\n",
    "        X, [one_sided_extrema, 1. - one_sided_extrema], axis=0\n",
    "    ) - m), axis=0)\n",
    "    s *= 2. / hypercube_edge_length\n",
    "    s[s <= np.finfo(X.dtype).eps] = 1.\n",
    "    return m, s\n",
    "\n",
    "\n",
    "def ball_volume_loginvdthroot(d):\n",
    "    \"\"\"Returns log(V**(-1/d)) where V is the d-volume of a unit ball.\"\"\"\n",
    "    return -np.log(np.pi) / 2. + gammaln(d / 2. + 1.) / d\n",
    "\n",
    "\n",
    "def nearestneighbour_distance_lowerbound(n, d):\n",
    "    \"\"\"Returns a lower bound on the expected nearest-neighbour distance of\n",
    "    n points uniformly distributed over a d-dimensional hypercube.\"\"\"\n",
    "    return np.exp(ball_volume_loginvdthroot(d) + betaln((n + 1.) / 2., 1. / d)\n",
    "                  - np.log(d))\n",
    "\n",
    "\n",
    "def nearestneighbour_distance(n, d):\n",
    "    \"\"\"Returns an estimate of the expected nearest neighbour distance of a row\n",
    "    in a real-world robustly normalized feature matrix of size n x d.\"\"\"\n",
    "    factor = 2. if d > 3 else 1.\n",
    "    return nearestneighbour_distance_lowerbound(d, n) / factor\n",
    "\n",
    "\n",
    "def knearestneighbour_distance(X, k=1, max_samples=1000):\n",
    "    \"\"\"Estimate the k-nearest neighbour distance.\"\"\"\n",
    "    S = X if X.shape[0] < max_samples else \\\n",
    "        X[np.random.choice(X.shape[0], max_samples, replace=False), :]\n",
    "    X2 = (X ** 2).sum(axis=1)[:, np.newaxis]\n",
    "    S2 = (S ** 2).sum(axis=1)[:, np.newaxis]\n",
    "    dist = X2 + (S2.T - 2. * (X @ S.T))\n",
    "    dist[dist <= np.sqrt(np.finfo(X.dtype).eps)] = np.inf\n",
    "    dist.sort(axis=0)\n",
    "    return np.median(np.sqrt(dist[k, :]))\n",
    "\n",
    "\n",
    "def kernel_radius_to_gamma(kernel_radius, n, d, kernel_value_at_radius=0.5):\n",
    "    \"\"\"Converts a kernel radius into a gamma value.\n",
    "\n",
    "    The kernel radius is defined as a multiple of the estimated nearest\n",
    "    neighbour distance of a robustly normalized feature matrix of size n x d,\n",
    "    and is the distance at which the kernel function attains the value\n",
    "    kernel_value_at_radius.\n",
    "\n",
    "    Gamma is hyperparameter of the RBF kernel exp(-gamma ||x-y||^2). Finding\n",
    "    a good value for gamma can be hard to reason about, while setting it in\n",
    "    terms of the kernel radius as a multiple of the nearest neighbour distance\n",
    "    should be much more intuitive.\n",
    "\n",
    "    To compute gamma given the kernel radius, we find:\n",
    "        exp(-gamma (kernel_radius * nn_dist)^2) = kernel_value_at_radius\n",
    "        gamma = -log(kernel_value_at_radius) (kernel_radius * nn_dist)^-2\n",
    "    \"\"\"\n",
    "    nn_dist = nearestneighbour_distance(n, d)\n",
    "    gamma = -np.log(kernel_value_at_radius) / (kernel_radius * nn_dist) ** 2.\n",
    "    return gamma\n",
    "\n",
    "\n",
    "class BaseAutoLSSVM(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self, kernel_radius=0.3, kernel_value_at_radius=0.5, mu=0.5):\n",
    "        self.kernel_radius = kernel_radius\n",
    "        self.kernel_value_at_radius = kernel_value_at_radius\n",
    "        self.mu = mu\n",
    "\n",
    "    def _normalize_X_y(self, X, y=None):\n",
    "        \"\"\"Remove median and scale to that 100*(1 - 2 * one_sided_extrema)%\n",
    "        of the data is approximately between -0.5 and 0.5.\"\"\"\n",
    "        if not hasattr(self, 'X_m_'):\n",
    "            self.X_m_, self.X_s_ = robust_normalizer(X)\n",
    "        X = (X - self.X_m_) / self.X_s_\n",
    "        if y is None:\n",
    "            return X\n",
    "        if not hasattr(self, 'y_m_'):\n",
    "            self.y_m_, self.y_s_ = robust_normalizer(y)\n",
    "        y = (y - self.y_m_) / self.y_s_\n",
    "        return X, y\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Validate input.\n",
    "        X, y = check_X_y(X, y, accept_sparse=None, dtype='numeric')\n",
    "        # Normalize input.\n",
    "        self.n_, self.d_ = X.shape\n",
    "        #X, y = self._normalize_X_y(X, y)\n",
    "        self.gamma_ = kernel_radius_to_gamma(\n",
    "            self.kernel_radius, self.n_, self.d_, self.kernel_value_at_radius)\n",
    "        # Train model.\n",
    "        self.K_ = pairwise_kernels(\n",
    "            X, metric='rbf', gamma=self.gamma_, n_jobs=-1)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Validate input.\n",
    "        check_is_fitted(self, 'K_')\n",
    "        X = check_array(X, accept_sparse=None, dtype='numeric')\n",
    "        # Predict with trained model.\n",
    "        return self.K_.mean() * np.ones((X.shape[0],))\n",
    "\n",
    "\n",
    "class AutoLSSVMRegressor(BaseAutoLSSVM):\n",
    "\n",
    "    def __init__(self, gamma=1.0, eta=1.0):\n",
    "#         super(AutoLSSVMRegressor, self).__init__(gamma=gamma, eta=eta)\n",
    "        super(AutoLSSVMRegressor, self).__init__()\n",
    "\n",
    "    def predict(self, X):\n",
    "        y = super(AutoLSSVMRegressor, self).predict(X)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/veruska/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoLSSVMRegressor(eta=None, gamma=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = BaseAutoLSSVM()\n",
    "model = AutoLSSVMRegressor()\n",
    "model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_array = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607, 0.9188607,\n",
       "       0.9188607, 0.9188607, 0.9188607, 0.9188607])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_array[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2c5fc7367c0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Bus Bunching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf_measure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "# Bus Bunching\n",
    "accuracy = accuracy_score(test_Y, pred_array)\n",
    "precision = precision_score(test_Y, pred_array)\n",
    "recall = recall_score(test_Y, pred_array)\n",
    "f_measure = f1_score(test_Y, pred_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \" + str(accuracy))\n",
    "print(\"Precision: \" + str(precision))\n",
    "print(\"Recall: \" + str(recall))\n",
    "print(\"F-measure: \" + str(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
